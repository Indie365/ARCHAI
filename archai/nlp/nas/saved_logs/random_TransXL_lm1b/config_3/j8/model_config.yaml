adaptive: true
affinity: socket_unique_interleaved
amp: apex
apex_amp_opt_level: O2
append_dataset: false
append_time: false
attn_type: 0
batch_chunk: 1
batch_size: 224
clamp_len: -1
clip: 0.25
clip_nonemb: false
cuda: true
cutoffs:
- 59997
- 99997
- 639997
- 793470
d_embed: 64
d_head: -1
d_inner:
- 1037
- 1516
- 1339
- 1539
- 1210
- 1154
d_model: 64
dataset: lm1b
debug: false
decay_rate: 0.5
div_val: 4
dllog_file: train_log.json
dropatt: 0.0
dropout: 0.0
dtype: null
emb_init: normal
emb_init_range: 0.01
eta_min: 0.0
eval_batch_size: 16
eval_interval: 5000
eval_max_steps: -1
eval_tgt_len: 32
experiment_name: j8
ext_len: 0
fear_terminate: false
fp16: false
get_params: false
gpu0_bsz: 32
init: normal
init_range: 0.1
init_std: 0.02
local_batch_size: null
local_rank: 7
log_all_ranks: false
log_interval: 10
lr: 0.00025
lr_min: 0.0
max_step: 100000
max_step_scheduler: null
mem_len: 32
mom: 0.0
multi_gpu: ddp
n_all_param: 8728949
n_head:
- 4
- 4
- 2
- 4
- 4
- 4
n_layer: 6
n_nonemb_param: 1130355
n_token: 793470
no_env: true
no_eval: false
not_tied: false
optim: adam
patience: 0
ppl_threshold: null
pre_lnorm: false
primer_conv: false
primer_square: false
proj_init_std: 0.01
restart: ''
roll: false
same_length: false
sample_softmax: -1
save_all: false
scheduler: cosine
seed: 1111
swap_mem: false
target_perplexity: null
target_throughput: null
tgt_len: 32
tie_projs:
- false
- false
- false
- false
tie_weight: true
tied: true
txtlog_file: train_log.log
use_cache: false
use_train: false
varlen: false
vocab: word
vocab_size: null
warmup_step: 20000
weight_decay: 0.0
weight_init_range: 0.1
weight_init_std: 0.02
weight_init_type: normal
