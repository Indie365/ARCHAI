config_0_j1:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j1
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 5
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 22753459
  n_head: 8
  n_layer: 1
  n_nonemb_param: 3412480
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j1
config_0_j2:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j2
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 26165939
  n_head: 8
  n_layer: 2
  n_nonemb_param: 6824960
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j2
config_0_j3:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j3
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 29578419
  n_head: 8
  n_layer: 3
  n_nonemb_param: 10237440
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j3
config_0_j4:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j4
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 32990899
  n_head: 8
  n_layer: 4
  n_nonemb_param: 13649920
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j4
config_0_j5:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j5
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 36403379
  n_head: 8
  n_layer: 5
  n_nonemb_param: 17062400
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j5
config_0_j6:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j6
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 39815859
  n_head: 8
  n_layer: 6
  n_nonemb_param: 20474880
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_0-dde91798/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139860.42481-374caff3-2f8a-4262-ae37-0038a8382abc/j6
config_1_j1:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j1
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 43228339
  n_head: 8
  n_layer: 7
  n_nonemb_param: 23887360
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j1
config_1_j2:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j2
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 46640819
  n_head: 8
  n_layer: 8
  n_nonemb_param: 27299840
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j2
config_1_j3:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j3
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 50053299
  n_head: 8
  n_layer: 9
  n_nonemb_param: 30712320
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j3
config_1_j4:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j4
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 53465779
  n_head: 8
  n_layer: 10
  n_nonemb_param: 34124800
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j4
config_1_j5:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j5
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 7
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 56878259
  n_head: 8
  n_layer: 11
  n_nonemb_param: 37537280
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j5
config_1_j6:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j6
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 60290739
  n_head: 8
  n_layer: 12
  n_nonemb_param: 40949760
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_1-ee8dd86d/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139775.03354-ef10c2d7-2e36-4bb4-8846-1d0c42a3652b/j6
config_2_j1:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j1
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 63703219
  n_head: 8
  n_layer: 13
  n_nonemb_param: 44362240
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139702.93393-1dba4457-0b97-4657-8eee-fa52d6347110/j1
config_2_j2:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j2
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 0
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 67115699
  n_head: 8
  n_layer: 14
  n_nonemb_param: 47774720
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139702.93393-1dba4457-0b97-4657-8eee-fa52d6347110/j2
config_2_j3:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j3
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 3
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 70528179
  n_head: 8
  n_layer: 15
  n_nonemb_param: 51187200
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139702.93393-1dba4457-0b97-4657-8eee-fa52d6347110/j3
config_2_j4:
  adaptive: true
  affinity: socket_unique_interleaved
  amp: apex
  apex_amp_opt_level: O2
  append_dataset: false
  append_time: false
  attn_type: 0
  batch_chunk: 2
  batch_size: 256
  clamp_len: -1
  clip: 0.25
  clip_nonemb: false
  cuda: true
  d_embed: 512
  d_head: 64
  d_inner: 2048
  d_model: 512
  data: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amltd1ebf9ece668699b883fe1eda0eb631a/dataroot/textpred/wikitext-103
  dataset: wt103
  debug: false
  decay_rate: 0.5
  div_val: 4
  dllog_file: train_log.json
  dropatt: 0.0
  dropout: 0.1
  emb_init: normal
  emb_init_range: 0.01
  eta_min: 0.001
  eval_batch_size: 16
  eval_interval: 5000
  eval_max_steps: -1
  eval_tgt_len: 192
  experiment_name: j4
  ext_len: 0
  fear_terminate: false
  fp16: false
  get_params: false
  gpu0_bsz: -1
  init: normal
  init_range: 0.1
  init_std: 0.02
  local_batch_size: null
  local_rank: 3
  log_all_ranks: false
  log_interval: 10
  lr: 0.01
  lr_min: 0.0
  max_step: 40000
  max_step_scheduler: null
  mem_len: 192
  mom: 0.0
  multi_gpu: ddp
  n_all_param: 73940659
  n_head: 8
  n_layer: 16
  n_nonemb_param: 54599680
  n_token: 267736
  no_env: true
  no_eval: false
  not_tied: false
  optim: jitlamb
  patience: 0
  ppl_threshold: null
  pre_lnorm: false
  proj_init_std: 0.01
  restart: ''
  roll: true
  same_length: false
  sample_softmax: -1
  save_all: false
  scheduler: cosine
  seed: 1111
  swap_mem: false
  target_perplexity: null
  target_throughput: null
  tgt_len: 192
  tied: true
  txtlog_file: train_log.log
  use_train: false
  varlen: false
  vocab: word
  vocab_size: null
  warmup_step: 1000
  weight_decay: 0.0
  work_dir: /mnt/batch/tasks/shared/LS_root/jobs/trainingwestus2/azureml/mojan_archai-f3e03b54-memformer_baselines-config_2-7a618620/mounts/amlt97f13f6a295a01df66eb92e1106f6ce5/projects/mojan_archai/amlt-results/7366139702.93393-1dba4457-0b97-4657-8eee-fa52d6347110/j4
